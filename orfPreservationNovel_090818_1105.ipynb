{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "%matplotlib inline\n",
    "\n",
    "gff3Cols=[\"seqid\",\"source\",\"type\",\"start\",\"end\",\"score\",\"strand\",\"phase\",\"attributes\"]\n",
    "novelSources=['CHESS','StringTie','FANTOM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BestRefSeq', 'GENCODE', 'StringTie', 'HAVANA', 'ENSEMBL', 'Curated Genomic', 'Gnomon', 'RefSeq', 'CHESS', 'FANTOM'}\n",
      "set of all gene_types in CHESS {'protein_coding', 'misc_RNA', 'lncRNA', 'antisense_RNA'}\n",
      "number of known protein-coding genes is: 22659\n",
      "the number of transcripts in protein-coding known genes is: 169965\n",
      "the number of CDSs associated with transcripts in protein-coding known genes is 129847\n"
     ]
    }
   ],
   "source": [
    "# first build a dataframe of all known transcripts per\n",
    "df_known_only=pd.read_csv(\"./chess2.02.gff\",sep=\"\\t\",names=gff3Cols)\n",
    "df_known_only.dropna(inplace=True,axis=0)\n",
    "df_known_only.reset_index(inplace=True,drop=True)\n",
    "df_known_only[\"start\"]=df_known_only[\"start\"].astype(int)\n",
    "df_known_only[\"end\"]=df_known_only[\"end\"].astype(int)\n",
    "\n",
    "# next we shall create the subset of all non-novel genes\n",
    "print(set(df_known_only[\"source\"]))\n",
    "df_known_only=df_known_only[~(df_known_only['source'].isin(novelSources))].reset_index(drop=True)\n",
    "\n",
    "# now let's isolate the protein-coding genes and their transcripts, exons and CDS\n",
    "\n",
    "# first let's extract IDs\n",
    "df_known_only[\"id\"]=df_known_only.attributes.str.split(\"ID=\",expand=True)[1].str.split(\";\",expand=True)[0]\n",
    "df_known_only[\"parent\"]=df_known_only.attributes.str.split(\"Parent=\",expand=True)[1].str.split(\";\",expand=True)[0]\n",
    "df_known_only[\"geneID\"]=np.where(df_known_only[\"type\"].isin(['transcript','exon','CDS']),df_known_only.parent.str.extract('(CHS.(\\d)*)',expand=True)[0],df_known_only['id'])\n",
    "# first create a tmpdf_known_only (to be removed right after) of just the genes, so we can get their coding potential\n",
    "tmp=df_known_only[df_known_only[\"type\"]==\"gene\"].reset_index(drop=True)\n",
    "# next let's extract information about the gene type\n",
    "tmp[\"gene_type\"]=tmp.attributes.str.split(\"GENE_TYPE=\",expand=True)[1].str.split(\";\",expand=True)[0].str.strip(\"\\n\")\n",
    "print(\"set of all gene_types in CHESS\",set(tmp[\"gene_type\"]))\n",
    "\n",
    "# now we can get a subset of all known protein_coding genes\n",
    "tmp=tmp[tmp[\"gene_type\"]==\"protein_coding\"].reset_index(drop=True)\n",
    "print(\"number of known protein-coding genes is: %d\"%len(tmp))\n",
    "# now we just need to get geneIDs for the protein_coding sequences\n",
    "setProtGenes_known_only=set(tmp[\"geneID\"])\n",
    "del tmp\n",
    "# df_known_only.drop([\"id\",\"parent\"],inplace=True,axis=1)\n",
    "df_known_only=df_known_only[df_known_only[\"geneID\"].isin(setProtGenes_known_only)].reset_index(drop=True)\n",
    "\n",
    "# next we would like to test whether all transcripts in these known protein-coding genes contain a CDS\n",
    "\n",
    "# first get a set of parent IDs for all CDSs\n",
    "cdsParents_known_only=set(df_known_only[df_known_only[\"type\"]==\"CDS\"][\"parent\"])\n",
    "# now form a set of IDs for all transcripts\n",
    "transIDs_known_only=set(df_known_only[df_known_only[\"type\"]==\"transcript\"][\"id\"])\n",
    "print(\"the number of transcripts in protein-coding known genes is: %d\\nthe number of CDSs associated with transcripts in protein-coding known genes is %d\"%(len(transIDs_known_only),len(cdsParents_known_only)))\n",
    "\n",
    "# First order of business is to find out how to get ORFs out of the gffs\n",
    "\n",
    "# one way would be to group all CDS-sequences from same transcript\n",
    "# and to compile all starts and ends into format similar to tlst\n",
    "# the tlst block format can then be used as a unique identifier of the intron chain as well as the orf in general\n",
    "# if multiple transcripts exist for the same gene with the same CDS - those can later be merged as well.\n",
    "# Otherwise a gene has isoforms coding different proteins\n",
    "cdsDF=df_known_only[df_known_only['type']=='CDS'].reset_index(drop=True)\n",
    "\n",
    "def formBlocks(series):\n",
    "    return \",\".join([str(x) for x in sorted(series.tolist())])\n",
    "\n",
    "cdsGDF=cdsDF.groupby(\"parent\").agg({'start':formBlocks,'end':formBlocks}).reset_index()\n",
    "mergedDF=cdsDF[['seqid','parent','strand']].merge(cdsGDF,on='parent',how='outer',indicator=True)\n",
    "assert len(mergedDF[mergedDF[\"_merge\"]==\"both\"])==len(mergedDF), \"ids don't match\"\n",
    "mergedDF.drop_duplicates(inplace=True)\n",
    "mergedDF.reset_index(drop=True,inplace=True)\n",
    "mergedDF.drop('_merge',inplace=True,axis=1)\n",
    "\n",
    "mergedDF['uid']=mergedDF[\"start\"]+\"-\"+mergedDF[\"end\"]\n",
    "mergedDF=mergedDF[['seqid','strand','parent','uid']]\n",
    "\n",
    "# now we can extract gene IDs and groupby them\n",
    "# we should count the total number of isoforms included\n",
    "# as well as the number of unique ORFs present for that gene\n",
    "\n",
    "# first get the gene ID\n",
    "mergedDF[\"gID\"]=mergedDF[\"parent\"].reset_index(drop=True).str.extract('(CHS.(\\d)*)',expand=True)[0]\n",
    "\n",
    "setKnownTranscripts=set(mergedDF[\"parent\"])\n",
    "setKnownGenes=set(mergedDF[\"gID\"])\n",
    "\n",
    "# now let's get rid of any duplicates in this dataframe\n",
    "mergedDF.drop_duplicates(['seqid','strand','gID','uid'],inplace=True)\n",
    "mergedDF.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the final number of known genes we are examining is: 16496\n",
      "the total number of novel transcripts in known genes we are examining is: 95974\n"
     ]
    }
   ],
   "source": [
    "# next build a dataframe of all novel transcripts and exons per known genes\n",
    "df=pd.read_csv(\"./chess2.02.gff\",sep=\"\\t\",names=gff3Cols)\n",
    "df.dropna(inplace=True,axis=0)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df[\"start\"]=df[\"start\"].astype(int)\n",
    "df[\"end\"]=df[\"end\"].astype(int)\n",
    "df[\"id\"]=df.attributes.str.split(\"ID=\",expand=True)[1].str.split(\";\",expand=True)[0]\n",
    "df[\"parent\"]=df.attributes.str.split(\"Parent=\",expand=True)[1].str.split(\";\",expand=True)[0]\n",
    "df[\"geneID\"]=np.where(df[\"type\"].isin(['transcript','exon','CDS']),df.parent.str.extract('(CHS.(\\d)*)',expand=True)[0],df['id'])\n",
    "\n",
    "df=df[(df[\"geneID\"].isin(setKnownGenes))&(df[\"source\"].isin(novelSources))&~((df[\"parent\"].isin(setKnownTranscripts))|(df[\"id\"].isin(setKnownTranscripts)))].reset_index(drop=True)\n",
    "\n",
    "# now we can further refine the original mergedDF by removing any genes that have no novel transcripts\n",
    "mergedDF=mergedDF[mergedDF['gID'].isin(set(df[\"geneID\"]))].reset_index(drop=True)\n",
    "print(\"the final number of known genes we are examining is: %d\"%(len(set(mergedDF[\"gID\"]))))\n",
    "\n",
    "exonDF=df[df['type']=='exon'].reset_index(drop=True)\n",
    "\n",
    "exonGDF=exonDF.groupby(\"parent\").agg({'start':formBlocks,'end':formBlocks}).reset_index()\n",
    "mergedExonDF=exonDF[['seqid','parent','strand']].merge(exonGDF,on='parent',how='outer',indicator=True)\n",
    "assert len(mergedExonDF[mergedExonDF[\"_merge\"]==\"both\"])==len(mergedExonDF), \"ids don't match\"\n",
    "mergedExonDF.drop_duplicates(inplace=True)\n",
    "mergedExonDF.reset_index(drop=True,inplace=True)\n",
    "mergedExonDF.drop('_merge',inplace=True,axis=1)\n",
    "\n",
    "mergedExonDF['uid']=mergedExonDF[\"start\"]+\"-\"+mergedExonDF[\"end\"]\n",
    "mergedExonDF=mergedExonDF[['seqid','strand','parent','uid']]\n",
    "\n",
    "# now we can extract gene IDs and groupby them\n",
    "# we should count the total number of isoforms included\n",
    "# as well as the number of unique ORFs present for that gene\n",
    "\n",
    "# first get the gene ID\n",
    "mergedExonDF[\"gID\"]=mergedExonDF[\"parent\"].reset_index(drop=True).str.extract('(CHS.(\\d)*)',expand=True)[0]\n",
    "\n",
    "# now let's get rid of any duplicates in this dataframe\n",
    "mergedExonDF.drop_duplicates(['seqid','strand','gID','uid'],inplace=True)\n",
    "mergedExonDF.reset_index(drop=True,inplace=True)\n",
    "\n",
    "print(\"the total number of novel transcripts in known genes we are examining is: %d\"%(len(set(mergedExonDF[\"parent\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['924432,925922,930155,931039,935772,939040,939275-924948,926013,930336,931089,935896,939129,939291', '925942,930155,931039,935772-926013,930336,931089,935793', '925942,930155,931039,935772,939040,939275,941144,942136,942410,942559,943253,943698,943908-926013,930336,931089,935896,939129,939460,941306,942251,942488,943058,943377,943808,944153', '930312,931039,935772,939040,939275,941144,942136,942410,942559,943253,943698,943908-930336,931089,935896,939129,939412,941306,942251,942488,943058,943377,943808,944151', '939275,941144,942136,942410,942559,943253,943698-939460,941306,942251,942488,943058,943377,944151']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqid</th>\n",
       "      <th>strand</th>\n",
       "      <th>parent</th>\n",
       "      <th>uid</th>\n",
       "      <th>gID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>CHS.39.3</td>\n",
       "      <td>924432,925922,930155,931039,935772,939040,9392...</td>\n",
       "      <td>CHS.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>CHS.39.11</td>\n",
       "      <td>925942,930155,931039,935772-926013,930336,9310...</td>\n",
       "      <td>CHS.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>CHS.39.13</td>\n",
       "      <td>925942,930155,931039,935772,939040,939275,9411...</td>\n",
       "      <td>CHS.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>CHS.39.16</td>\n",
       "      <td>930312,931039,935772,939040,939275,941144,9421...</td>\n",
       "      <td>CHS.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>CHS.39.21</td>\n",
       "      <td>939275,941144,942136,942410,942559,943253,9436...</td>\n",
       "      <td>CHS.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seqid strand     parent                                                uid  \\\n",
       "2  chr1      +   CHS.39.3  924432,925922,930155,931039,935772,939040,9392...   \n",
       "3  chr1      +  CHS.39.11  925942,930155,931039,935772-926013,930336,9310...   \n",
       "4  chr1      +  CHS.39.13  925942,930155,931039,935772,939040,939275,9411...   \n",
       "5  chr1      +  CHS.39.16  930312,931039,935772,939040,939275,941144,9421...   \n",
       "6  chr1      +  CHS.39.21  939275,941144,942136,942410,942559,943253,9436...   \n",
       "\n",
       "      gID  \n",
       "2  CHS.39  \n",
       "3  CHS.39  \n",
       "4  CHS.39  \n",
       "5  CHS.39  \n",
       "6  CHS.39  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we create a dictionary of all exon chains of known transcripts on known genes\n",
    "def groupBlocks(series):\n",
    "    return series.tolist()\n",
    "\n",
    "geneBlocks=mergedDF.groupby(\"gID\").agg({'uid':groupBlocks}).reset_index()\n",
    "\n",
    "knownChains=pd.Series(geneBlocks.uid.values,index=geneBlocks.gID).to_dict()\n",
    "print(knownChains[\"CHS.39\"])\n",
    "mergedDF[mergedDF[\"gID\"]=='CHS.39']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we can proceed to write a comparrison function to parse these exon-intron chains\n",
    "# the function is not expected to be particularly fast\n",
    "# however, what I need is just to get an answer, so...\n",
    "\n",
    "def checkCompat(orf,exons):\n",
    "    # first convert the orf into lists\n",
    "    tmp=orf.split(\"-\")\n",
    "    orfStarts=[int(x) for x in tmp[0].split(\",\")]\n",
    "    orfEnds=[int(x) for x in tmp[-1].split(\",\")]\n",
    "    \n",
    "    # next we need to parse the exons in the same manner\n",
    "    tmp=exons.split(\"-\")\n",
    "    exonStarts=[int(x) for x in tmp[0].split(\",\")]\n",
    "    exonEnds=[int(x) for x in tmp[-1].split(\",\")]\n",
    "    numExons=len(exonStarts)\n",
    "    \n",
    "    # now we need to compare them to one another\n",
    "    # there could be three possibilities which we shall use the following return codes for:\n",
    "    # 0 - ORF fits entirely within the exon\n",
    "    # 1 - section of the ORF is lost without a frameshift\n",
    "    # 2 - an extra section is added to the ORF without causing a framesift\n",
    "    # 3 - there is a frameshift due to an extra section added to the ORF\n",
    "    # 4 - there is a frameshift due to a section removed from the ORF\n",
    "    # 5 - ORF is trimmed at the end - perhaps the exon should be extended???\n",
    "    # 6 - potentially missing start codon - if the beginning of the ORF is trimmed\n",
    "    \n",
    "    assert len(orfStarts)==len(orfEnds),\"wrong CDS chain passed, length don't match: \"+orf\n",
    "    assert len(exonStarts)==len(exonEnds),\"wrong exon chain passed, length don't match: \"+exons\n",
    "#     assert len(orfStarts)<=len(exonStarts),\"There are more segments in ORF than in the exon chain. ORF: \"+orf+\" ; Exons-chain: \"+exons\n",
    "    \n",
    "    frameShift=0\n",
    "    modification=0\n",
    "    \n",
    "    orfPos=0\n",
    "    exonPos=-1\n",
    "    numOrfSegments=len(orfStarts)\n",
    "    for es,ee in zip(exonStarts,exonEnds):\n",
    "        exonPos+=1\n",
    "        curOrfStart=orfStarts[orfPos]\n",
    "        curOrfEnd=orfEnds[orfPos]\n",
    "        if ee<curOrfStart:\n",
    "            # if this happens before the first ORF - then good\n",
    "            # otherwise we have an insertion and need to check for a frameshift\n",
    "            if orfPos==0:\n",
    "                continue\n",
    "            else:\n",
    "                frameShift=((ee+1)-es)%3\n",
    "                if frameShift==0:\n",
    "                    modification=2\n",
    "                else:\n",
    "                    return 3\n",
    "        elif es<=curOrfStart and ee==curOrfEnd: # ORF within exon and fits nicely - exon/CDS segment share end\n",
    "            if orfPos==numOrfSegments-1: # ORF fits and is done\n",
    "                return modification\n",
    "            else: # ORF continues\n",
    "                if exonPos==numExons-1: # trimmed based on having a shorter exon chain\n",
    "                    return 5\n",
    "                orfPos+=1\n",
    "        elif es<=curOrfStart and ee>curOrfEnd: # could be the proper end of the ORF or a signal for modification\n",
    "            if orfPos==numOrfSegments-1: # ORF fits and is done\n",
    "                return modification\n",
    "            else: # ORF does not match current exon chain\n",
    "                return 9999999\n",
    "        elif es<=curOrfStart and ee<curOrfEnd: # could be the end of the ORF, or a signal for modification\n",
    "            if orfPos==numOrfSegments-1: # ORF fits, is trimmed at the end and is done\n",
    "                return 5\n",
    "            else: # ORF does not match current exon chain.\n",
    "                return 9999999\n",
    "        elif es>curOrfStart and ee==curOrfEnd: # frameshift due to exon beginning later\n",
    "            if orfPos==0: # potentially missing start codon due to ORF trimming at start\n",
    "                return 6\n",
    "            frameShift=(es-curOrfStart)%3\n",
    "            if orfPos==numOrfSegments-1:\n",
    "                if frameShift==0:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 4\n",
    "            else:\n",
    "                return 9999999\n",
    "        elif es>curOrfStart and ee>curOrfEnd:\n",
    "            frameShift=(es-curOrfStart)%3\n",
    "            if orfPos==numOrfSegments-1:\n",
    "                if frameShift==0:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return 4\n",
    "            else:\n",
    "                if frameShift==0:\n",
    "                    return 9999999\n",
    "                else:\n",
    "                    return 4 # just abandon - not going to be any worth - it's already a frameshift\n",
    "        else:\n",
    "            break\n",
    "                \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "# what if we try sets\n",
    "# resChain=[]\n",
    "# for t in chain2:\n",
    "#     resChain=resChain+list(range(t[0],t[1]))\n",
    "# resOrf=[]\n",
    "# for t in orf3:\n",
    "#     resOrf=resOrf+list(range(t[0],t[1]))\n",
    "    \n",
    "# print(set(resOrf)-set(resChain))\n",
    "# print(set(resChain)-set(resOrf))\n",
    "\n",
    "def checkCompat(orf,chain):\n",
    "    global count\n",
    "    if count%10000==0:\n",
    "        print(count)\n",
    "    count+=1\n",
    "    tmp=orf.split(\"-\")\n",
    "    orfStarts=[int(x) for x in tmp[0].split(\",\")]\n",
    "    orfEnds=[int(x) for x in tmp[-1].split(\",\")]\n",
    "    \n",
    "    # next we need to parse the exons in the same manner\n",
    "    tmp=chain.split(\"-\")\n",
    "    chainStarts=[int(x) for x in tmp[0].split(\",\")]\n",
    "    chainEnds=[int(x) for x in tmp[-1].split(\",\")]\n",
    "    \n",
    "    orf=[]\n",
    "    for t in zip(orfStarts,orfEnds):\n",
    "        orf+=list(range(t[0],t[1]+1))\n",
    "    \n",
    "    chain=[]\n",
    "    for t in zip(chainStarts,chainEnds):\n",
    "        chain+=list(range(t[0],t[1]+1))\n",
    "    \n",
    "    # now remove anything in the chain that is before or after the start and end of the ORF\n",
    "    chain=[x for x in chain if x>=orf[0] and x<=orf[-1]]\n",
    "    \n",
    "    orf=set(orf)\n",
    "    chain=set(chain)\n",
    "    \n",
    "    # now get set differences\n",
    "    orf_chain=orf-chain\n",
    "    chain_orf=chain-orf\n",
    "    \n",
    "    if len(orf_chain)==0 and len(chain_orf)==0:\n",
    "        return 0\n",
    "    \n",
    "    allMis=[]\n",
    "    for k, g in groupby(enumerate(orf_chain), lambda ix : ix[0] - ix[1]):\n",
    "        allMis.append(list(map(itemgetter(1), g)))\n",
    "    for k, g in groupby(enumerate(chain_orf), lambda ix : ix[0] - ix[1]):\n",
    "        allMis.append(list(map(itemgetter(1), g)))\n",
    "    # now just need to figure out what kind of frameshifts we've got here\n",
    "    offFrame=0 # number of extra or missing bases that do result in a frameshift\n",
    "    onFrame=0 # number of extra or missing bases that do not result in a frameshift\n",
    "    \n",
    "    # for now this will be a very easy thing to do\n",
    "    # would be better to have a method for computing how many bases are in off-frame vs on-frame regions\n",
    "    for mis in allMis:\n",
    "        if not len(mis)%3==0:\n",
    "            return 2\n",
    "    return 1\n",
    "    \n",
    "orf3=\"1,7-3,15\"\n",
    "chain17=\"1,9,15-2,9,18\"\n",
    "checkCompat(orf3,chain17)\n",
    "\n",
    "# need to deal with the special case when the first base of the start codon is missing\n",
    "\n",
    "# next apply this function to the entirety of the dataframe\n",
    "\n",
    "def compareToAll(row): # performs comparrisons for all\n",
    "    # stop if a single match is found - otherwise\n",
    "    finalRes=[]\n",
    "    for chain in knownChains[row['gID']]:\n",
    "        res=checkCompat(chain,row['uid'])\n",
    "        if res==0:\n",
    "            return 0\n",
    "        finalRes.append(res) # return the smallest code\n",
    "        # this assumes that the smalles code is the best - sorting needs to be done in a custom way here\n",
    "        # but the idea is the same\n",
    "    \n",
    "    return min(finalRes)\n",
    "\n",
    "mergedExonDF[\"match\"]=mergedExonDF.apply(lambda row: compareToAll(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqid</th>\n",
       "      <th>strand</th>\n",
       "      <th>parent</th>\n",
       "      <th>uid</th>\n",
       "      <th>gID</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [seqid, strand, parent, uid, gID, match]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedExonDF[(mergedExonDF[\"match\"]==1)&(mergedExonDF[\"match\"]==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent good: 0.5022089315856377\n",
      "percent bad: 0.4977910684143622\n"
     ]
    }
   ],
   "source": [
    "print(\"percent good:\",len(mergedExonDF[(mergedExonDF[\"match\"]==0)|(mergedExonDF[\"match\"]==1)])/len(mergedExonDF))\n",
    "print(\"percent bad:\",len(mergedExonDF[mergedExonDF[\"match\"]==2])/len(mergedExonDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# next we need to examine the known transcripts more closely\n",
    "# in order to find out the rates of 0/1/2 in there\n",
    "# for each protein coding gene we should do the following\n",
    "# 1. get a group of all transcripts\n",
    "# 2. for each transcript\n",
    "#    - compare to all other transcripts in a group\n",
    "# 3. record how many transcripts per gene have a 0,1,2 when compared to the other ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we shall build a dataframe of all known exons to compare against known CDS sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDF.head().apply(lambda row: compareToAll(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wonder if we could use anything else here like gffcompare - unlikely\n",
    "# However, we might also need to account for a missing start codon as a special code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next logical step would be to analyze existing/known ORFs only\n",
    "# to see how frequently ORFs within the same gene have frameshifts/deletions/insertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lastly, we need to investigate novel genes and the transcripts annotated there\n",
    "# to see if the distribution of frameshifts/insertions/deletions is similar\n",
    "# to that observed for the known transcripts inside known genes\n",
    "\n",
    "# all in all these steps should answer the question completely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one other important consideration is (not critical at the moment, but will be necessary for the final results)\n",
    "\n",
    "At the moment we are removing duplicates of any transcripts which appear to have identical intron-exon chain,\n",
    "whihc is done to avoid making comparisons multiple times\n",
    "\n",
    "What we should be doing instead is:\n",
    "1. grouping them by the same ['seqid','strand','blocks']\n",
    "2. keeping track of the number that went into the same group\n",
    "3. keeping only one single representative for the group, thus effectively performing the same function as the drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
